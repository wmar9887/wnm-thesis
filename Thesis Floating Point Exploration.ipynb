{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61a54b9a-b144-41de-92e7-c96066ddab33",
   "metadata": {},
   "source": [
    "# Formally verified Adder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3791c2-b5e6-4838-b83e-c4a814388006",
   "metadata": {},
   "source": [
    "Simple 8 bit adder function using bit masking and shifting \n",
    "\n",
    "Create a loop to check result of all inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0712cb2b-5961-4750-bbc4-49ceab691933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition of an variable-bit adder\n",
    "def adder_var_bit(a, b, length):\n",
    "    #create variables necessary to catch all conditions.\n",
    "    carryFlag = 0\n",
    "    zeroFlag = 0\n",
    "    overflowFlag = 0\n",
    "    result = 0\n",
    "\n",
    "    # Extract bits for arithmetic use.\n",
    "    for i in range(length):\n",
    "        # curr_a and curr_b is a 1 or 0 value at a position i in the 8 bit value.\n",
    "        curr_a = (a >> i) & 1\n",
    "        curr_b = (b >> i) & 1\n",
    "        \n",
    "        # We or the bits together to create binary addition making sure to include a\n",
    "        # potential carry value, and place it in the sum_bit variable.\n",
    "        sum_bit = curr_a ^ curr_b ^ carryFlag\n",
    "\n",
    "        # We then set the carryFlag using boolean logic on the other two bits as well as \n",
    "        # check the carryFlag is not already active.\n",
    "        carryFlag = (curr_a & curr_b) | (curr_a & carryFlag) | (curr_b & carryFlag)\n",
    "        \n",
    "        # Then we append the current working bit onto the result value.\n",
    "        result |= (sum_bit << i)\n",
    "        \n",
    "        # Check for overflow on final bit calculation\n",
    "        if (carryFlag & 1) != ((result >> length-1) & 0):\n",
    "            overflowFlag = 1\n",
    "    return result, overflowFlag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a85de37a-12c3-4d2f-9b3f-2df09d6381cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "a = 0b10000000\n",
    "b = 0b10000001\n",
    "add, overflowFlag = adder_var_bit(a, b, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d21f2203-cab1-482b-88a9-372ff8cbb0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Sum: 00000001\n",
      "Decimal Sum 1\n",
      "Overflow Flag: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Binary Sum:\", bin(add)[2:].zfill(8))\n",
    "print(\"Decimal Sum\", add)\n",
    "print(\"Overflow Flag:\", overflowFlag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76df4854-9120-4234-beca-75036ff8c3e0",
   "metadata": {},
   "source": [
    "# MiniFloat Adder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c46f51a-48b6-4945-a813-7bbf3f8350e8",
   "metadata": {},
   "source": [
    "Using an 8 bit FP value that has 1 sign bit, 4 exponent bits, and 3 mantissa bits\n",
    "\n",
    "How is it calculated??\n",
    "\n",
    "X<e,m> =  | E = 0,     (-1)^S * 2^(1-B) * (0 + F * 2^-m) | (denormal)\n",
    "\n",
    "otherwise | (-1)^S * 2^(E-B) * (1 + F * 2^-m) | (normal)\n",
    "\n",
    "where B = 2^(e - 1) - 1\n",
    "\n",
    "Example: if we have the 8-bit value of 0 0110 010\n",
    "\n",
    "sign = negative\n",
    "\n",
    "exponent in decimal = 5\n",
    "\n",
    "mantissa in decimal = 2\n",
    "\n",
    "B = 2^4 - 1 = 7\n",
    "\n",
    "(denormal calculation) -> (-1)^0 * 2^(1-7) * (0 + 2*2^-3) = 1 * 0.015625 * 0.25 = 3.90625e-3\n",
    "\n",
    "(normal calculation) -> (-1)^0 * 2^(6-7) * (1 + 2*2^-3) = 1 * 0.5 + 0.125 = 6.25e-1\n",
    "\n",
    "Minimum denormal values X<e,m> = 0 0000 001 -> 1 * 2^-6 * (1*2^-3) = 2^-9.\n",
    "\n",
    "Maximum positive normal is then: X<e,m> = 0 1111 111 -> 1 * 2^(15-7) * (1 + 7*2^-3) = 480\n",
    "\n",
    "If denormal numbers are used then all values where the mantissa is equal to 0 tend to 0.\n",
    "\n",
    "0 1111 000 -> 0\n",
    "\n",
    "1 1111 000 -> 0\n",
    "\n",
    "0 0000 000 -> 0\n",
    "\n",
    "1 0000 000 -> -0\n",
    "\n",
    "Use normal numbers? What is the purpose of denormal numbers (subnormal etc)\n",
    "\n",
    "Computer Arithmetic https://www.amazon.com.au/Digital-Arithmetic-Kaufmann-Computer-Architecture/dp/1558607986\n",
    "Patterson and hennerson computer organisation and design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da0d62d-eafa-4a31-82df-07535bc1688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mf43adder(a, b):\n",
    "    carryFlag = 0\n",
    "    overflowFlag = 0\n",
    "    zeroFlag = 0\n",
    "    result = 0;\n",
    "\n",
    "    e = 4\n",
    "    m = 3\n",
    "    B = 2**(e-1)-1\n",
    "    \n",
    "    F_a = a & 0b111\n",
    "    F_b = b & 0b111\n",
    "\n",
    "    shift_a = a >> 3\n",
    "    shift_b = b >> 3\n",
    "\n",
    "    E_a = shift_a & 0b1111\n",
    "    E_b = shift_b & 0b1111\n",
    "\n",
    "    E_diff = E_a - E_b\n",
    "\n",
    "    if (E_diff > 0):\n",
    "        F_b <<= E_diff\n",
    "        E_b += E_diff\n",
    "\n",
    "    elif (E_diff < 0):\n",
    "        E_diff = -E_diff\n",
    "        F_a <<= E_diff\n",
    "        E_a += E_diff\n",
    "\n",
    "    sum_F = F_a + F_b\n",
    "    sum_E = E_a\n",
    "    if sum_F >= 8:\n",
    "        sum_F &= 0b111  # Keep only the lower 3 bits\n",
    "        sum_E += 1  # Increase exponent\n",
    "    \n",
    "    result = (-1)**0 * 2**(sum_E-B) * (1+sum_F*2**(-m))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07048ed1-3871-41a4-9066-4785c173fadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mf43adder function calculation: 0.4375\n"
     ]
    }
   ],
   "source": [
    "a = 0b00011001\n",
    "b = 0b00101010\n",
    "\n",
    "print(\"mf43adder function calculation:\", mf43adder(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b91a5df8-0b22-42d7-82e6-099f2743cd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Input: 0.0703125\n",
      "B Input: 0.3125\n",
      "Final floating point value: 0.3828125\n"
     ]
    }
   ],
   "source": [
    "a = (-1)**0 * 2**(3-7) * (1+1*2**(-3))\n",
    "print(\"A Input:\", a)\n",
    "b = (-1)**0 * 2**(5-7) * (1+2*2**(-3))\n",
    "print(\"B Input:\", b)\n",
    "c = a + b\n",
    "print(\"Final floating point value:\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5a218e-5b31-4442-b69e-5f313e7c7f0f",
   "metadata": {},
   "source": [
    "### Clearly these do not match. Further testing/understanding required on method of adding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf9cb7-9f59-44f7-8f95-c605990af171",
   "metadata": {},
   "source": [
    "## Kulisch Accumulator "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9c5263-96df-460a-b508-3634d5699826",
   "metadata": {},
   "source": [
    "A Kulisch accumulator is a type of accumulator designed to minimize round-off errors in numerical computations, particularly in floating-point arithmetic. It was developed by mathematician Peter Kulisch in the late 1980s.\n",
    "\n",
    "In numerical computations, especially those involving floating-point arithmetic, round-off errors can accumulate and lead to inaccuracies in the results. The Kulisch accumulator aims to mitigate these errors by using extended precision arithmetic and employing a method called \"compensation\" or \"renormalization\" to reduce the accumulation of errors.\n",
    "\n",
    "The basic idea behind the Kulisch accumulator is to perform arithmetic operations in a higher precision than the final result and then adjust the result to the desired precision while minimizing the accumulation of round-off errors. This approach can improve the accuracy of numerical computations, especially in iterative algorithms where errors can propagate over multiple computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b0aaf-f51f-4af1-a36f-8ea8c1acbc01",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daeb711-2672-4738-8e70-5d3998f64834",
   "metadata": {},
   "source": [
    "Need to continue working on these applications to ensure we can achieve correct values, then further apply it to multiplication. Once we have this a preliminary attempt at verification should be made before moving onto the the Block MiniFloat version. From there we can attempt take what we have learned and build a FMA which we can verify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d8744-8cfb-40d6-80bb-3087a4f520ba",
   "metadata": {},
   "source": [
    "## Floating Point Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffea8eb6-7278-44b7-b7f9-0fc66c9996bf",
   "metadata": {},
   "source": [
    "https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6694f390-5d92-48b4-bba3-1b209acc4d6e",
   "metadata": {},
   "source": [
    "#### Rounding Error types:\n",
    "ULPS - Units in the last place. \n",
    "When a calculation results in a value such $.0314159$ but is then represented as $3.14\\times10^0$, we say that this representation is in error by $.159$ ULP. Essentially if the value were to be computed to infinite precision, the difference between the inifite precision value and the representation is the difference from the last incorrect signiifcant value.\n",
    "\n",
    "Relative Error - Simply the difference between the two numbers divided by the real number. Using our example above we see that we get:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34ace17-1cfc-4a1e-8e6e-77c3e8800a68",
   "metadata": {},
   "source": [
    "$$\\frac{3.14159 - 3.14\\times10^0}{3.14159} = \\frac{0.00159}{3.14159} = 0.0005$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e0ec23-e1c6-4d27-a154-a61400706127",
   "metadata": {},
   "source": [
    "Since their is a range of numbers that the floating point values can be based on the significand and exponents widths, we see that the range of error that can arise is between two values: $$\\frac{1}{2}\\beta^{-p}\\leq\\frac{1}{2}ulp\\leq\\frac{\\beta}{2}\\beta^{-p}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf2585d-4e3a-4d28-9988-6f8eaa4c52e9",
   "metadata": {},
   "source": [
    "In particular we are might be concerned with when the relative error corresponds to $.5 ulp$. This can vary by a factor of $\\beta$, and is commonly referred to as the $wobble$ factor. Setting $\\epsilon$ to the largest boundary in the above inequality, we can say that the a real number rounded to the closest floating point number, the relative error is always bounded by the exponent. This is referred to as $\\textit{machine epsilon}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069e68a-a940-4cea-b62b-8c49897e8868",
   "metadata": {},
   "source": [
    "### Theorem 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c23031-c2d9-4465-90df-06d9bfde1616",
   "metadata": {},
   "source": [
    "Using a floating-point format with parameters $\\beta$ and p, and computing differences using p digits, the relative error of the result can be as large as $\\beta$ - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60ae6ba-8589-4bf7-be2c-8048326b8004",
   "metadata": {},
   "source": [
    "### Proof 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35422235-8bd6-45b0-abe0-7e7e10d9ce04",
   "metadata": {},
   "source": [
    "A relative error of $\\beta - 1$ in the expression $x - y$ occurs when $x = 1.00...0$ and $y =  .\\rho\\rho...\\rho$, where $\\rho = \\beta - 1$. Here $y$ has p digits (all equal to $\\rho$). The exact difference is then $x-y = \\beta^{-p}$. However, critically, when working with p digits, the rightmost digit of $y$ gets shifted off, and so the computed difference is $\\beta^{-p+1}$. \n",
    "Thus the error is: $$\\beta^{-p} - \\beta^{-p+1} = \\beta^{-p}(\\beta - 1)$$ \n",
    "and the relative error is: $$\\frac{\\beta^{-p}(\\beta - 1)}{\\beta^{-p}} = \\beta - 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01e7030-8fe7-4009-9ab8-6daaeb3c8021",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c74ca4-e209-4c4d-8379-21a8a50311af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc0b4d28-5f5e-4d23-8feb-1c5bdd67cea7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
